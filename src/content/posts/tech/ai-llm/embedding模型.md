---
title: embedding模型相关知识
published: 2025-12-27
description: "现在的大模型，RAG等都需要把输入进行embedding，那embedding模型选型的标准是什么呢？以及embedding的原理，一般embedding是怎么实现的，以及如何评估embedding的效果好不好？"
image: "./img/embedding.png"
tags: ["LLM", "RAG"]
category: LLM
draft: false
---
## 一、Embedding是什么
Embedding（嵌入），本质上是一种降维与特征提取的技术。它的核心作用是将非结构化的文本、图像、音频等信息，转化为计算机能“理解”和“计算”的数学形式——即高维空间中的向量（一组数字）。

计算机无法直接理解单词的含义。通过Embedding，语义相似的词或句子（如“猫”和“猫咪”）在向量空间中距离会很近，语义不同的（如“猫”和“汽车”）则距离较远。这使得我们可以用向量距离计算（如余弦相似度）来度量语义相似性，从而进行检索、比较和推理。

## 二、Embedding的原理
Embedding 的本质是将离散符号（如词、句子、用户、图像等）映射为低维、稠密的连续向量，**使得语义或结构相似的对象在向量空间中距离更近**。其演进可分为三个阶段：**静态嵌入 → 动态上下文嵌入 → 对比学习增强的语义表征**。

#### 1.静态词嵌入（Static Embedding）
特点：每个词对应一个固定向量，不随上下文变化，采用“查表法”（Lookup Table）实现。  
 - Word2Vec(Skip-gram/CBOW) 通过局部上下文预测任务学习向量，遵循“共现频率越高，向量越接近”的原则。   
 - GloVe(Global Vectors) 基于全局词-词共现矩阵，结合统计信息与矩阵分解，兼顾局部与全局语义。   

局限：无法处理一词多义（如“苹果”在不同语境下应有不同表示）。   
✅ 训练快、资源消耗低，轻量高效｜❌ 语义表达僵化，缺乏上下文感知能力
#### 2.动态上下文嵌入（Contextual Embedding）
核心：基于 Transformer Encoder + 自注意力机制，为每个 token 生成依赖上下文的动态向量。   
训练方式：掩码语言建模（MLM，如 BERT），迫使模型学习双向语义依赖。   
关键特性：同一词在不同语境下生成不同向量（如水果中的苹果 vs 苹果手机中的苹果）。   
句向量提取：由于模型输出的是 token 级向量，需通过池化（Pooling） 得到句子级表示
- Mean Pooling（主流）：对所有 token 向量取平均，语义稳定；
- CLS Pooling：取 [CLS] token 向量，原始 BERT 设计，但实测效果常不如 Mean；
通常配合 L2 归一化，便于后续余弦相似度计算。   
✅ 上下文敏感｜⚠️ 需合理池化才能获得高质量句向量
#### 3.语义对齐增强：对比学习（Contrastive Learning）
目标：优化向量空间的语义对齐性与区分度，已成为现代 Embedding 模型（如BGE、E5、GTE）的核心训练范式。   
原理：给定一个查询（Query），拉近其与正样本（如匹配的句子、答案）的距离，推开负样本。   
损失函数：InfoNCE Loss，在大规模正负样本对上进行端到端微调。    
输出处理：仍依赖池化（通常 Mean Pooling）+ L2 归一化，形成最终 Embedding。     
✅ 显著提升检索、聚类、语义匹配效果｜依赖高质量标注或构造的对比数据
#### 4.跨模态嵌入（Cross-Modal Embedding）
将不同模态（如文本、图像）映射到统一语义空间，实现跨模态理解与检索。   
架构：双塔模型（Two-Tower）  
文本塔：Transformer（如 BERT）   
图像塔：ViT 或 CNN   
训练方式：跨模态对比学习（如 CLIP）   
使“狗的照片”与“一张狗的图片”在向量空间中靠近。   
应用：图文搜索、多模态推荐、生成模型对齐等。   
✅ 支持跨模态语义对齐｜需大规模图文对数据

## 三、Embedding选型的标准
选择 Embedding 模型并非“越大越好”，而是要根据任务特性、算力预算和数据隐私等维度进行综合权衡。以下是核心选型标准：   
1. 任务适配与领域能力  
    * **通用 vs. 领域专用：**  
        * **通用模型：** 如 OpenAI `text-embedding-3` 或 BAAI 的 `BGE-M3`，适用于大多数日常语义搜索。  
        * **领域模型：** 若业务涉及医疗（病灶分析）、法律（条文解读）或金融（不良资产核销），必须优先考虑在特定语料上微调过的模型，否则通用模型难以捕捉行业专有名词的精确含义。  
    * **多模态需求：** 若场景包含图片、音频或视频检索，需选择如 `Amazon Nova MME` 或 `CLIP` 等原生支持多模态对齐的模型，确保不同模态能映射在同一向量空间。
2. 多语言与多功能支持   
    * **跨语言检索：** 如果数据源包含中、英、日等多种语言，需选用支持 **Multilingual** 的模型（如 `multilingual-e5` 或 `BGE-M3`），以实现跨语言的语义匹配。
    * **多任务统一：** 现代顶尖模型（如 BGE-M3）通常支持“三合一”功能：密集检索（Dense）、稀疏检索（Sparse/BM25）和多向量检索（Multi-vector），适合需要混合搜索的复杂 RAG 场景。
3. 维度灵活性与存储成本
    * **套娃嵌入 (Matryoshka Embedding)：** 这是 2024-2025 年的主流趋势。如 `text-embedding-3` 系列，允许你直接截断向量维度（如从 3072 降至 256）而几乎不损失性能。
    * **高维度 (1024+)：** 语义丰富，适合对精度要求极高的长文本检索，但存储开销大。
    * **低维度 (256-512)：** 检索极快，适合大规模实时搜索（亿级数据）或移动端部署。
4. 上下文长度 (Context Window) 
    * **分块策略：** 模型的 Token 限制直接决定了你的“切片”大小。
    * **短文本模型 (512 tokens)：** 适合句子或短段落匹配。
    * **长文本模型 (8k - 32k tokens)：** 适合整篇文档或法律长合同的嵌入。需注意：将过长文本压缩进一个向量可能会导致语义稀释。
5. 部署模式与成本核算
    * **开源自托管 (Open-weights)：**    
        * **优势：** 数据完全私有、无调用费、可深度定制（微调）。
        * **挑战：** 需要 GPU 算力（如 A10/L40s），需承担运维成本。推荐：BGE、GTE、E5 系列。
    * **闭源 API (Proprietary)：** 
        * **优势：** 开箱即用、性能顶尖、免运维。
        * **挑战：** 数据需出境、按量计费、长年累月成本较高。推荐：OpenAI、Cohere、Gemini。
6. 性能评测参考指标   
    * **排行榜 (Leaderboards)：** 参考 **MTEB (Massive Text Embedding Benchmark)** 或中文榜单 **C-MTEB**。
    * **实测数据：** 榜单高分不代表业务高分。务必在自己的业务数据集上测试 **Recall@K (召回率)** 和 **P99 Latency (延迟)**。

💡 快速决策决策树
1. **追求极致精度、预算充足、数据可公有：** 选 OpenAI `text-embedding-3-large`。
2. **核心要求数据私有、中文场景为主：** 选智源 `BGE-v1.5` 或 `BGE-M3`。
3. **高并发、低延迟、资源受限：** 选 `bge-small-zh` 或利用套娃技术截断后的低维向量。
4. **长文档解析、复杂 RAG 系统：** 选支持长上下文且具备混合检索能力（Sparse+Dense）的模型。


## 四、如何评估Embedding的效果
📊 Embedding 模型效果评估与指标   
评估 Embedding 模型不能只看单一分数，通常需要从内部语义质量、下游检索效果和系统性能三个维度进行综合评定。

在自测前，建议优先参考行业公认的权威榜单：**MTEB**（Massive Text Embedding Benchmark）是目前全球最主流的文本嵌入评估基准，涵盖 8 大类、58 项任务（包括检索、聚类、分类、语义相似度等），提供统一的综合得分，已成为模型选型的“黄金标准”；针对中文场景，**C-MTEB**（Chinese-MTEB）则专门评估模型在中文语义理解上的能力，是中文业务选型的重要依据。

根据任务类型不同，核心评价指标有所侧重：

- **检索类任务**（如 RAG、搜索）最关注：
  - **Recall@K**：前 K 个结果中包含正确答案的比例，例如 Recall@5=0.8 表示 80% 的查询在前 5 个结果中命中。
  - **MRR**（Mean Reciprocal Rank）：衡量首个相关结果的平均排名，越靠前越好。
  - **nDCG@K**：考虑相关性等级的排序指标，不仅看是否相关，还看高相关结果是否排在前面，是目前最科学的检索评估指标。

- **语义相似度任务**常用：
  - **STS**（Semantic Textual Similarity）：通过计算模型输出的余弦相似度与人工标注分数之间的 **Spearman 秩相关系数**，评估语义对齐质量。

- **聚类与分类任务**则关注：
  - **Silhouette Score**（轮廓系数）：衡量聚类“类内紧密、类间分离”的程度。
  - **Accuracy / F1-score**：将 Embedding 作为特征输入简单分类器，评估其表征判别能力。

评估可分为两类：**任务无关评估**和**任务相关评估**。前者在 MTEB、STS-B、BEIR 等标准数据集上进行，用于衡量模型的通用语义能力；后者则在你自己的业务数据上构建评估集（如问答对、点击日志或人工标注相关文档），以 Recall@K、MRR 等核心指标验证真实效果。

需要特别注意：**通用能力强 ≠ 业务效果好**。推荐做法是：先通过 MTEB / C-MTEB 快速筛选候选模型，再用自有数据做最终验证和选型。同时，还需综合考虑向量维度（如是否支持套娃嵌入降维）、推理延迟和存储成本，确保模型在效果与效率之间取得最佳平衡。

## reference
banner图使用通义万象生成，内容写作使用了Gemini和Qwen-max辅助整理归纳  
[mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)    
[MMTEB: Massive Multilingual Text Embedding Benchmark](https://arxiv.org/pdf/2502.13595)
[认识MTEB榜单](https://meetcoding.cn/lm/mteb.html)